name: Generate sitemap & robots

on:
  workflow_dispatch:

jobs:
  gen:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4

      - name: Generate files
        shell: bash
        run: |
          set -euo pipefail
          BASE="https://mojaf-sa.com"
          TODAY="$(date +%F)"

          # Collect HTML files but exclude non-indexable stuff
          mapfile -t FILES < <(find . -type f -name '*.html' \
            -not -path './.git/*' \
            -not -path './.github/*' \
            -not -path './node_modules/*' \
            -not -path './_turbo_en/*' \
            -not -path './blogs/*' \
            -not -name '404.html' \
            -not -name 'header-footer-snippet.html' \
            | sed 's|^\./||')

          URLS=()
          for f in "${FILES[@]}"; do
            bn="$(basename "$f")"
            if [[ "$bn" == "index.html" ]]; then
              d="$(dirname "$f")"
              if [[ "$d" == "." ]]; then
                u="$BASE/"
              else
                u="$BASE/$d/"
              fi
            else
              u="$BASE/$f"
            fi
            # Normalize blog routes to a single canonical: /blog/
            if [[ "$u" == "$BASE/blog" || "$u" == "$BASE/blog.html" ]]; then
              u="$BASE/blog/"
            fi
            URLS+=("$u")
          done

          # Unique + sort + tiny normalization
          mapfile -t URLS < <(printf "%s\n" "${URLS[@]}" \
            | sed 's|//|/|g; s|:/|://|g' \
            | sort -u)

          # Write sitemap.xml
          {
            echo '<?xml version="1.0" encoding="UTF-8"?>'
            echo '<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">'
            for u in "${URLS[@]}"; do
              echo "  <url>"
              echo "    <loc>${u}</loc>"
              echo "    <lastmod>${TODAY}</lastmod>"
              echo "  </url>"
            done
            echo '</urlset>'
          } > sitemap.xml

          # Write robots.txt (absolute sitemap URL)
          cat > robots.txt <<EOF
User-agent: *
Allow: /

Sitemap: ${BASE}/sitemap.xml
EOF

      - name: Commit & push
        run: |
          if [[ -n "$(git status --porcelain)" ]]; then
            git config user.name "github-actions[bot]"
            git config user.email "github-actions[bot]@users.noreply.github.com"
            git add sitemap.xml robots.txt
            git commit -m "chore: regenerate sitemap & robots from repo structure"
            git push
          else
            echo "No changes to commit"
          fi
